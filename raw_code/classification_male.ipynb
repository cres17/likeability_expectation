{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6o_-xo_l3Oc",
        "outputId": "4d9c500c-7a40-4b9f-e05d-c69505785155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets wandb focal-loss -q\n",
        "!wandb login --relogin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ KoBigBird 기반 Binary 호감도 변화 분류 모델 (발화 + 문맥 + MaxPool + BCE)\n",
        "\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Constants\n",
        "MODEL_NAME = \"monologg/kobigbird-bert-base\"\n",
        "MAX_LEN = 4096\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10\n",
        "LR = 2e-5\n",
        "\n",
        "# ✅ Dataset (input_text → utterance + context로 분리해 concat)\n",
        "class DialogueDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        utterance = item.get(\"target_utterance\", \"\")  # 주된 발화\n",
        "        context = item.get(\"dialogue_history\", \"\")     # 문맥\n",
        "        combined = utterance + \" [SEP] \" + context      # 발화 + 문맥\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            combined,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
        "\n",
        "        label = 1.0 if float(item[\"label_male\"]) > 0.5 else 0.0  # Binary\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"label\": torch.tensor(label, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# ✅ Model with [CLS] + max-pooling and BCE output\n",
        "class KoBigBirdBinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        hidden = self.encoder.config.hidden_size\n",
        "        self.classifier = nn.Linear(hidden * 2, 1)  # binary output\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_emb = outputs.last_hidden_state[:, 0, :]                     # [CLS]\n",
        "        pooled = torch.max(outputs.last_hidden_state, dim=1).values     # max pooling\n",
        "        combined = torch.cat([cls_emb, pooled], dim=-1)\n",
        "        return self.classifier(combined).squeeze(-1)  # (B,) → Binary logit\n",
        "\n",
        "# ✅ Load data\n",
        "with open(\"dialogues_human.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    all_data = [json.loads(line) for line in f if line.strip()]\n",
        "\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset = DialogueDataset(train_data, tokenizer)\n",
        "test_dataset = DialogueDataset(test_data, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# ✅ Initialize\n",
        "model = KoBigBirdBinaryClassifier().cuda()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "wandb.init(project=\"huggingface\", name=\"kobigbird-binary-utterance-context\")\n",
        "wandb.watch(model, log_freq=100)\n",
        "\n",
        "# ✅ Training\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].cuda()\n",
        "        attention_mask = batch['attention_mask'].cuda()\n",
        "        labels = batch['label'].cuda()\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        wandb.log({\"train_loss\": loss.item()})\n",
        "\n",
        "# ✅ Evaluation\n",
        "model.eval()\n",
        "preds, labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].cuda()\n",
        "        attention_mask = batch['attention_mask'].cuda()\n",
        "        label = batch['label'].cuda()\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        prob = torch.sigmoid(logits)\n",
        "        pred = (prob > 0.5).long()\n",
        "\n",
        "        preds.extend(pred.cpu().numpy())\n",
        "        labels.extend(label.cpu().long().numpy())\n",
        "\n",
        "acc = accuracy_score(labels, preds)\n",
        "f1 = f1_score(labels, preds, average=\"binary\")\n",
        "conf_mat = confusion_matrix(labels, preds)\n",
        "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", conf_mat)\n",
        "\n",
        "wandb.log({\"accuracy\": acc, \"f1\": f1})\n",
        "\n",
        "# ✅ Save model & upload as artifact\n",
        "torch.save(model.state_dict(), \"kobigbird_binary_model.pt\")\n",
        "artifact = wandb.Artifact(\"kobigbird-binary-model\", type=\"model\")\n",
        "artifact.add_file(\"kobigbird_binary_model.pt\")\n",
        "wandb.log_artifact(artifact)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "Cc7BAM9yl34S",
        "outputId": "c8522738-04c0-4d24-f529-29b0283a8628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>macro_f1</td><td>▁</td></tr><tr><td>train_loss</td><td>▇▅▄▆▄▇▆▇▅▅▅▃▄▅▄▂█▂▂▂▂▃▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57143</td></tr><tr><td>macro_f1</td><td>0.36574</td></tr><tr><td>train_loss</td><td>0.0299</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">kobigbird-3class</strong> at: <a href='https://wandb.ai/cres4205-sangmyung-university/huggingface/runs/kel4mc3d' target=\"_blank\">https://wandb.ai/cres4205-sangmyung-university/huggingface/runs/kel4mc3d</a><br> View project at: <a href='https://wandb.ai/cres4205-sangmyung-university/huggingface' target=\"_blank\">https://wandb.ai/cres4205-sangmyung-university/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250517_024607-kel4mc3d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250517_031504-44zcd072</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cres4205-sangmyung-university/huggingface/runs/44zcd072' target=\"_blank\">kobigbird-binary-utterance-context</a></strong> to <a href='https://wandb.ai/cres4205-sangmyung-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cres4205-sangmyung-university/huggingface' target=\"_blank\">https://wandb.ai/cres4205-sangmyung-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cres4205-sangmyung-university/huggingface/runs/44zcd072' target=\"_blank\">https://wandb.ai/cres4205-sangmyung-university/huggingface/runs/44zcd072</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n",
            "100%|██████████| 28/28 [00:39<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6071, F1: 0.7556\n",
            "Confusion Matrix:\n",
            " [[ 0 11]\n",
            " [ 0 17]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Artifact kobigbird-binary-model>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1번째 https://wandb.ai/cres4205-sangmyung-university/huggingface/runs/9ypgun68  \n",
        "\n",
        "Accuracy: 0.6071, Macro-F1: 0.2519"
      ],
      "metadata": {
        "id": "Xp5nmeex1jlB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4hRfIJ61h87"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}